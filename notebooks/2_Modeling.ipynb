{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model  # For visualizing your model architecture\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Reserve part of the data for validation\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 456 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creation of Data Split and Augmentation of Training Set\n",
    "batch_size = 32\n",
    "img_size = 224\n",
    "target_size = (img_size, img_size)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'.\\data\\processed',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Or 'categorical' if multi-class\n",
    "    color_mode='grayscale',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r'.\\data\\processed',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghass\\Desktop\\DMSA-Net\\DMSA\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m802,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc3 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">998,625</span> (3.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m998,625\u001b[0m (3.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">998,625</span> (3.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m998,625\u001b[0m (3.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "def DMSA_Net():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(input_shape=(img_size,img_size,1),filters=64,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "  model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "  model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "  model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "  model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "  model.add(Flatten(name='flatten'))\n",
    "  model.add(Dense(128, activation='relu', name='fc1'))\n",
    "  model.add(Dense(64, activation='relu', name='fc2'))\n",
    "  model.add(Dense(32, activation='relu', name='fc3'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "model=DMSA_Net()\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "# Check model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghass\\Desktop\\DMSA-Net\\DMSA\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.6063 - loss: 0.6897 - val_accuracy: 0.6161 - val_loss: 0.6689\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 806ms/step - accuracy: 0.6215 - loss: 0.6720 - val_accuracy: 0.6161 - val_loss: 0.6691\n",
      "Epoch 3/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 790ms/step - accuracy: 0.5939 - loss: 0.6787 - val_accuracy: 0.6161 - val_loss: 0.6653\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 792ms/step - accuracy: 0.6711 - loss: 0.6478 - val_accuracy: 0.6161 - val_loss: 0.6779\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 802ms/step - accuracy: 0.6086 - loss: 0.6819 - val_accuracy: 0.6161 - val_loss: 0.6746\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 806ms/step - accuracy: 0.6277 - loss: 0.6795 - val_accuracy: 0.6161 - val_loss: 0.6772\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 784ms/step - accuracy: 0.6448 - loss: 0.6742 - val_accuracy: 0.6161 - val_loss: 0.6705\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 791ms/step - accuracy: 0.6407 - loss: 0.6658 - val_accuracy: 0.6161 - val_loss: 0.6670\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 806ms/step - accuracy: 0.6449 - loss: 0.6539 - val_accuracy: 0.6161 - val_loss: 0.6662\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 784ms/step - accuracy: 0.6058 - loss: 0.6681 - val_accuracy: 0.6161 - val_loss: 0.6670\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 777ms/step - accuracy: 0.6182 - loss: 0.6675 - val_accuracy: 0.6161 - val_loss: 0.6660\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 821ms/step - accuracy: 0.6219 - loss: 0.6662 - val_accuracy: 0.6161 - val_loss: 0.6667\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 787ms/step - accuracy: 0.5940 - loss: 0.6772 - val_accuracy: 0.6161 - val_loss: 0.6665\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 777ms/step - accuracy: 0.6032 - loss: 0.6750 - val_accuracy: 0.6161 - val_loss: 0.6660\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 780ms/step - accuracy: 0.6137 - loss: 0.6642 - val_accuracy: 0.6161 - val_loss: 0.6681\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 782ms/step - accuracy: 0.6225 - loss: 0.6696 - val_accuracy: 0.6161 - val_loss: 0.6694\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.5968 - loss: 0.6737 - val_accuracy: 0.6161 - val_loss: 0.6674\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 778ms/step - accuracy: 0.6119 - loss: 0.6727 - val_accuracy: 0.6161 - val_loss: 0.6670\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 777ms/step - accuracy: 0.6018 - loss: 0.6756 - val_accuracy: 0.6161 - val_loss: 0.6667\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 781ms/step - accuracy: 0.6131 - loss: 0.6594 - val_accuracy: 0.6161 - val_loss: 0.6658\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 786ms/step - accuracy: 0.6221 - loss: 0.6710 - val_accuracy: 0.6161 - val_loss: 0.6657\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.6180 - loss: 0.6622 - val_accuracy: 0.6161 - val_loss: 0.6670\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 785ms/step - accuracy: 0.5959 - loss: 0.6796 - val_accuracy: 0.6161 - val_loss: 0.6243\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 773ms/step - accuracy: 0.6137 - loss: 0.6494 - val_accuracy: 0.6161 - val_loss: 0.6423\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 787ms/step - accuracy: 0.6526 - loss: 0.6070 - val_accuracy: 0.6161 - val_loss: 0.6341\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 802ms/step - accuracy: 0.5987 - loss: 0.6645 - val_accuracy: 0.6161 - val_loss: 0.6035\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.5941 - loss: 0.6241 - val_accuracy: 0.6161 - val_loss: 0.6193\n",
      "Epoch 28/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6130 - loss: 0.6117 - val_accuracy: 0.6161 - val_loss: 0.6217\n",
      "Epoch 29/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6072 - loss: 0.6088 - val_accuracy: 0.6161 - val_loss: 0.6044\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.5987 - loss: 0.6535 - val_accuracy: 0.6161 - val_loss: 0.6398\n",
      "Epoch 31/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6323 - loss: 0.6237 - val_accuracy: 0.6071 - val_loss: 0.6235\n",
      "Epoch 32/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6146 - loss: 0.6169 - val_accuracy: 0.5804 - val_loss: 0.6344\n",
      "Epoch 33/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6242 - loss: 0.6112 - val_accuracy: 0.6964 - val_loss: 0.6396\n",
      "Epoch 34/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6495 - loss: 0.6090 - val_accuracy: 0.6786 - val_loss: 0.6171\n",
      "Epoch 35/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.6685 - loss: 0.5654 - val_accuracy: 0.6071 - val_loss: 0.6252\n",
      "Epoch 36/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 4s/step - accuracy: 0.6361 - loss: 0.5876 - val_accuracy: 0.7232 - val_loss: 0.6351\n",
      "Epoch 37/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 817ms/step - accuracy: 0.7102 - loss: 0.5347 - val_accuracy: 0.6250 - val_loss: 0.6344\n",
      "Epoch 38/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6803 - loss: 0.5475 - val_accuracy: 0.7500 - val_loss: 0.5751\n",
      "Epoch 39/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4s/step - accuracy: 0.7073 - loss: 0.5307 - val_accuracy: 0.7589 - val_loss: 0.5687\n",
      "Epoch 40/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.7650 - loss: 0.4771 - val_accuracy: 0.7857 - val_loss: 0.4728\n",
      "Epoch 41/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.7750 - loss: 0.4666 - val_accuracy: 0.7768 - val_loss: 0.4965\n",
      "Epoch 42/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.7495 - loss: 0.4781 - val_accuracy: 0.7857 - val_loss: 0.4776\n",
      "Epoch 43/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4s/step - accuracy: 0.7994 - loss: 0.3798 - val_accuracy: 0.7857 - val_loss: 0.5384\n",
      "Epoch 44/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.7973 - loss: 0.4025 - val_accuracy: 0.7946 - val_loss: 0.4777\n",
      "Epoch 45/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.8090 - loss: 0.4124 - val_accuracy: 0.8214 - val_loss: 0.5096\n",
      "Epoch 46/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.8032 - loss: 0.4128 - val_accuracy: 0.8304 - val_loss: 0.4476\n",
      "Epoch 47/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.8003 - loss: 0.4437 - val_accuracy: 0.7500 - val_loss: 0.5386\n",
      "Epoch 48/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.7626 - loss: 0.4790 - val_accuracy: 0.8036 - val_loss: 0.4782\n",
      "Epoch 49/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8402 - loss: 0.3307 - val_accuracy: 0.8125 - val_loss: 0.4856\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.8383 - loss: 0.3592 - val_accuracy: 0.8393 - val_loss: 0.4711\n",
      "Epoch 51/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8385 - loss: 0.3248 - val_accuracy: 0.8393 - val_loss: 0.4207\n",
      "Epoch 52/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.8617 - loss: 0.3138 - val_accuracy: 0.8304 - val_loss: 0.4090\n",
      "Epoch 53/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8405 - loss: 0.3699 - val_accuracy: 0.8571 - val_loss: 0.4246\n",
      "Epoch 54/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4s/step - accuracy: 0.8135 - loss: 0.3914 - val_accuracy: 0.8482 - val_loss: 0.3877\n",
      "Epoch 55/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.8716 - loss: 0.2908 - val_accuracy: 0.8571 - val_loss: 0.3926\n",
      "Epoch 56/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.8549 - loss: 0.3155 - val_accuracy: 0.8393 - val_loss: 0.3491\n",
      "Epoch 57/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 794ms/step - accuracy: 0.8625 - loss: 0.3262 - val_accuracy: 0.8750 - val_loss: 0.3402\n",
      "Epoch 58/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 806ms/step - accuracy: 0.8610 - loss: 0.2948 - val_accuracy: 0.8482 - val_loss: 0.3774\n",
      "Epoch 59/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 776ms/step - accuracy: 0.8618 - loss: 0.3040 - val_accuracy: 0.8304 - val_loss: 0.3651\n",
      "Epoch 60/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.8810 - loss: 0.3115 - val_accuracy: 0.8839 - val_loss: 0.3551\n",
      "Epoch 61/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 747ms/step - accuracy: 0.8921 - loss: 0.3015 - val_accuracy: 0.8571 - val_loss: 0.3536\n",
      "Epoch 62/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 772ms/step - accuracy: 0.8991 - loss: 0.2427 - val_accuracy: 0.8571 - val_loss: 0.3843\n",
      "Epoch 63/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.8780 - loss: 0.2917 - val_accuracy: 0.7946 - val_loss: 0.4689\n",
      "Epoch 64/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8860 - loss: 0.2946 - val_accuracy: 0.8304 - val_loss: 0.3908\n",
      "Epoch 65/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.8610 - loss: 0.2795 - val_accuracy: 0.8482 - val_loss: 0.3887\n",
      "Epoch 66/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8938 - loss: 0.2982 - val_accuracy: 0.8214 - val_loss: 0.4712\n",
      "Epoch 67/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.9042 - loss: 0.2815 - val_accuracy: 0.8214 - val_loss: 0.4181\n",
      "Epoch 68/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.9029 - loss: 0.2617 - val_accuracy: 0.8125 - val_loss: 0.4444\n",
      "Epoch 69/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.8570 - loss: 0.3348 - val_accuracy: 0.8750 - val_loss: 0.3804\n",
      "Epoch 70/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8786 - loss: 0.2971 - val_accuracy: 0.8571 - val_loss: 0.3809\n",
      "Epoch 71/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.9057 - loss: 0.2421 - val_accuracy: 0.8393 - val_loss: 0.4032\n",
      "Epoch 72/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 777ms/step - accuracy: 0.8416 - loss: 0.3103 - val_accuracy: 0.8571 - val_loss: 0.3780\n",
      "Epoch 73/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9016 - loss: 0.2503 - val_accuracy: 0.8661 - val_loss: 0.3953\n",
      "Epoch 74/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.8884 - loss: 0.2690 - val_accuracy: 0.8839 - val_loss: 0.4557\n",
      "Epoch 75/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.8966 - loss: 0.2583 - val_accuracy: 0.8214 - val_loss: 0.4231\n",
      "Epoch 76/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.8807 - loss: 0.2713 - val_accuracy: 0.8304 - val_loss: 0.4199\n",
      "Epoch 77/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 771ms/step - accuracy: 0.9102 - loss: 0.2282 - val_accuracy: 0.8661 - val_loss: 0.4708\n",
      "Epoch 78/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 775ms/step - accuracy: 0.8922 - loss: 0.2356 - val_accuracy: 0.8571 - val_loss: 0.4531\n",
      "Epoch 79/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.8937 - loss: 0.2446 - val_accuracy: 0.8750 - val_loss: 0.4131\n",
      "Epoch 80/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 762ms/step - accuracy: 0.9283 - loss: 0.2069 - val_accuracy: 0.8571 - val_loss: 0.4473\n",
      "Epoch 81/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 751ms/step - accuracy: 0.8884 - loss: 0.2858 - val_accuracy: 0.8750 - val_loss: 0.3269\n",
      "Epoch 82/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9056 - loss: 0.2469 - val_accuracy: 0.8661 - val_loss: 0.3821\n",
      "Epoch 83/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 802ms/step - accuracy: 0.8960 - loss: 0.2525 - val_accuracy: 0.8661 - val_loss: 0.4499\n",
      "Epoch 84/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 752ms/step - accuracy: 0.8974 - loss: 0.2542 - val_accuracy: 0.8571 - val_loss: 0.4075\n",
      "Epoch 85/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 775ms/step - accuracy: 0.9196 - loss: 0.2168 - val_accuracy: 0.8839 - val_loss: 0.3856\n",
      "Epoch 86/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.8866 - loss: 0.2409 - val_accuracy: 0.8661 - val_loss: 0.3779\n",
      "Epoch 87/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9147 - loss: 0.2157 - val_accuracy: 0.8571 - val_loss: 0.4839\n",
      "Epoch 88/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 813ms/step - accuracy: 0.8938 - loss: 0.2878 - val_accuracy: 0.8661 - val_loss: 0.3945\n",
      "Epoch 89/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.8813 - loss: 0.2236 - val_accuracy: 0.8482 - val_loss: 0.4409\n",
      "Epoch 90/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 762ms/step - accuracy: 0.9152 - loss: 0.2100 - val_accuracy: 0.8482 - val_loss: 0.3950\n",
      "Epoch 91/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 752ms/step - accuracy: 0.8864 - loss: 0.2582 - val_accuracy: 0.8661 - val_loss: 0.3539\n",
      "Epoch 92/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761ms/step - accuracy: 0.9258 - loss: 0.1740 - val_accuracy: 0.8571 - val_loss: 0.4549\n",
      "Epoch 93/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 756ms/step - accuracy: 0.9028 - loss: 0.2498 - val_accuracy: 0.7946 - val_loss: 0.4434\n",
      "Epoch 94/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 760ms/step - accuracy: 0.8874 - loss: 0.2534 - val_accuracy: 0.8661 - val_loss: 0.3836\n",
      "Epoch 95/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 772ms/step - accuracy: 0.9058 - loss: 0.2058 - val_accuracy: 0.8750 - val_loss: 0.3628\n",
      "Epoch 96/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9053 - loss: 0.2010 - val_accuracy: 0.8750 - val_loss: 0.3714\n",
      "Epoch 97/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.9160 - loss: 0.2135 - val_accuracy: 0.8393 - val_loss: 0.5022\n",
      "Epoch 98/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 791ms/step - accuracy: 0.8974 - loss: 0.2514 - val_accuracy: 0.8125 - val_loss: 0.4335\n",
      "Epoch 99/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9217 - loss: 0.2175 - val_accuracy: 0.8571 - val_loss: 0.3663\n",
      "Epoch 100/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.9055 - loss: 0.2266 - val_accuracy: 0.8750 - val_loss: 0.3802\n",
      "Epoch 101/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 774ms/step - accuracy: 0.8972 - loss: 0.1981 - val_accuracy: 0.8482 - val_loss: 0.4018\n",
      "Epoch 102/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 759ms/step - accuracy: 0.9378 - loss: 0.1928 - val_accuracy: 0.8036 - val_loss: 0.4801\n",
      "Epoch 103/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 762ms/step - accuracy: 0.8803 - loss: 0.2753 - val_accuracy: 0.8482 - val_loss: 0.3883\n",
      "Epoch 104/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 772ms/step - accuracy: 0.8921 - loss: 0.2662 - val_accuracy: 0.9018 - val_loss: 0.3504\n",
      "Epoch 105/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.9196 - loss: 0.2153 - val_accuracy: 0.8661 - val_loss: 0.3749\n",
      "Epoch 106/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 760ms/step - accuracy: 0.9402 - loss: 0.2059 - val_accuracy: 0.8839 - val_loss: 0.3651\n",
      "Epoch 107/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9358 - loss: 0.1591 - val_accuracy: 0.8750 - val_loss: 0.3827\n",
      "Epoch 108/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 764ms/step - accuracy: 0.9093 - loss: 0.2029 - val_accuracy: 0.8571 - val_loss: 0.4594\n",
      "Epoch 109/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 752ms/step - accuracy: 0.9293 - loss: 0.1903 - val_accuracy: 0.8393 - val_loss: 0.4433\n",
      "Epoch 110/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9271 - loss: 0.1967 - val_accuracy: 0.8750 - val_loss: 0.4345\n",
      "Epoch 111/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 752ms/step - accuracy: 0.9221 - loss: 0.1942 - val_accuracy: 0.8839 - val_loss: 0.3495\n",
      "Epoch 112/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9060 - loss: 0.2049 - val_accuracy: 0.8393 - val_loss: 0.3776\n",
      "Epoch 113/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 765ms/step - accuracy: 0.9205 - loss: 0.1950 - val_accuracy: 0.8571 - val_loss: 0.3763\n",
      "Epoch 114/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 772ms/step - accuracy: 0.9375 - loss: 0.1782 - val_accuracy: 0.8750 - val_loss: 0.3774\n",
      "Epoch 115/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 778ms/step - accuracy: 0.9360 - loss: 0.2179 - val_accuracy: 0.8750 - val_loss: 0.3632\n",
      "Epoch 116/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.9312 - loss: 0.1963 - val_accuracy: 0.8929 - val_loss: 0.3707\n",
      "Epoch 117/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 771ms/step - accuracy: 0.9408 - loss: 0.1785 - val_accuracy: 0.8750 - val_loss: 0.4576\n",
      "Epoch 118/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9286 - loss: 0.1758 - val_accuracy: 0.8661 - val_loss: 0.4779\n",
      "Epoch 119/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 753ms/step - accuracy: 0.9443 - loss: 0.1563 - val_accuracy: 0.8839 - val_loss: 0.4780\n",
      "Epoch 120/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.9530 - loss: 0.1424 - val_accuracy: 0.8750 - val_loss: 0.4306\n",
      "Epoch 121/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 772ms/step - accuracy: 0.9123 - loss: 0.1813 - val_accuracy: 0.8304 - val_loss: 0.4695\n",
      "Epoch 122/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 776ms/step - accuracy: 0.9592 - loss: 0.1527 - val_accuracy: 0.8571 - val_loss: 0.4148\n",
      "Epoch 123/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.9168 - loss: 0.1765 - val_accuracy: 0.8839 - val_loss: 0.4240\n",
      "Epoch 124/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9225 - loss: 0.1996 - val_accuracy: 0.8661 - val_loss: 0.4526\n",
      "Epoch 125/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 771ms/step - accuracy: 0.9091 - loss: 0.2158 - val_accuracy: 0.8750 - val_loss: 0.5014\n",
      "Epoch 126/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761ms/step - accuracy: 0.9288 - loss: 0.1904 - val_accuracy: 0.8750 - val_loss: 0.5294\n",
      "Epoch 127/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 764ms/step - accuracy: 0.9221 - loss: 0.1763 - val_accuracy: 0.8661 - val_loss: 0.5498\n",
      "Epoch 128/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 805ms/step - accuracy: 0.9412 - loss: 0.1549 - val_accuracy: 0.9107 - val_loss: 0.4819\n",
      "Epoch 129/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.9488 - loss: 0.1451 - val_accuracy: 0.9018 - val_loss: 0.5405\n",
      "Epoch 130/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 765ms/step - accuracy: 0.9375 - loss: 0.1427 - val_accuracy: 0.8661 - val_loss: 0.5525\n",
      "Epoch 131/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 769ms/step - accuracy: 0.9517 - loss: 0.1197 - val_accuracy: 0.8750 - val_loss: 0.5567\n",
      "Epoch 132/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9558 - loss: 0.0988 - val_accuracy: 0.8750 - val_loss: 0.6046\n",
      "Epoch 133/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.9379 - loss: 0.1784 - val_accuracy: 0.8661 - val_loss: 0.4948\n",
      "Epoch 134/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 796ms/step - accuracy: 0.9578 - loss: 0.1142 - val_accuracy: 0.8750 - val_loss: 0.5775\n",
      "Epoch 135/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 780ms/step - accuracy: 0.9453 - loss: 0.1344 - val_accuracy: 0.8929 - val_loss: 0.5498\n",
      "Epoch 136/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 756ms/step - accuracy: 0.9484 - loss: 0.1276 - val_accuracy: 0.8839 - val_loss: 0.5527\n",
      "Epoch 137/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.9335 - loss: 0.1555 - val_accuracy: 0.8661 - val_loss: 0.6352\n",
      "Epoch 138/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 762ms/step - accuracy: 0.9045 - loss: 0.2203 - val_accuracy: 0.8571 - val_loss: 0.6799\n",
      "Epoch 139/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 771ms/step - accuracy: 0.9186 - loss: 0.1823 - val_accuracy: 0.8839 - val_loss: 0.5902\n",
      "Epoch 140/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9490 - loss: 0.1413 - val_accuracy: 0.8571 - val_loss: 0.6979\n",
      "Epoch 141/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761ms/step - accuracy: 0.9526 - loss: 0.1171 - val_accuracy: 0.8393 - val_loss: 0.6135\n",
      "Epoch 142/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 764ms/step - accuracy: 0.9671 - loss: 0.0945 - val_accuracy: 0.8393 - val_loss: 0.8036\n",
      "Epoch 143/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9594 - loss: 0.1292 - val_accuracy: 0.8482 - val_loss: 0.7520\n",
      "Epoch 144/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9358 - loss: 0.1441 - val_accuracy: 0.8750 - val_loss: 0.5869\n",
      "Epoch 145/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 801ms/step - accuracy: 0.9417 - loss: 0.1514 - val_accuracy: 0.8661 - val_loss: 0.5051\n",
      "Epoch 146/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.9554 - loss: 0.0941 - val_accuracy: 0.8750 - val_loss: 0.5904\n",
      "Epoch 147/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9550 - loss: 0.1644 - val_accuracy: 0.8839 - val_loss: 0.5166\n",
      "Epoch 148/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9541 - loss: 0.1284 - val_accuracy: 0.8839 - val_loss: 0.6209\n",
      "Epoch 149/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9717 - loss: 0.1177 - val_accuracy: 0.8571 - val_loss: 0.6188\n",
      "Epoch 150/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9602 - loss: 0.0913 - val_accuracy: 0.8750 - val_loss: 0.6277\n",
      "Epoch 151/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 769ms/step - accuracy: 0.9852 - loss: 0.0680 - val_accuracy: 0.8750 - val_loss: 0.7222\n",
      "Epoch 152/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.9694 - loss: 0.0862 - val_accuracy: 0.8839 - val_loss: 0.6147\n",
      "Epoch 153/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9650 - loss: 0.1350 - val_accuracy: 0.8661 - val_loss: 0.5787\n",
      "Epoch 154/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 765ms/step - accuracy: 0.9511 - loss: 0.1321 - val_accuracy: 0.8750 - val_loss: 0.6090\n",
      "Epoch 155/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9463 - loss: 0.1393 - val_accuracy: 0.8571 - val_loss: 0.6168\n",
      "Epoch 156/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9780 - loss: 0.0774 - val_accuracy: 0.8571 - val_loss: 0.8151\n",
      "Epoch 157/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 775ms/step - accuracy: 0.9389 - loss: 0.1246 - val_accuracy: 0.8661 - val_loss: 0.7049\n",
      "Epoch 158/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 779ms/step - accuracy: 0.9607 - loss: 0.1013 - val_accuracy: 0.8571 - val_loss: 0.7462\n",
      "Epoch 159/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 771ms/step - accuracy: 0.9801 - loss: 0.0680 - val_accuracy: 0.8661 - val_loss: 0.6993\n",
      "Epoch 160/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.9714 - loss: 0.0784 - val_accuracy: 0.8661 - val_loss: 0.7689\n",
      "Epoch 161/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9549 - loss: 0.1094 - val_accuracy: 0.8661 - val_loss: 0.6388\n",
      "Epoch 162/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 765ms/step - accuracy: 0.9475 - loss: 0.1513 - val_accuracy: 0.8571 - val_loss: 0.6151\n",
      "Epoch 163/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9660 - loss: 0.1027 - val_accuracy: 0.8929 - val_loss: 0.6700\n",
      "Epoch 164/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.9693 - loss: 0.0742 - val_accuracy: 0.8839 - val_loss: 0.7054\n",
      "Epoch 165/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 756ms/step - accuracy: 0.9744 - loss: 0.0620 - val_accuracy: 0.9018 - val_loss: 0.8054\n",
      "Epoch 166/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 754ms/step - accuracy: 0.9657 - loss: 0.1322 - val_accuracy: 0.9018 - val_loss: 0.7280\n",
      "Epoch 167/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9474 - loss: 0.1549 - val_accuracy: 0.8750 - val_loss: 0.6251\n",
      "Epoch 168/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 769ms/step - accuracy: 0.9462 - loss: 0.1430 - val_accuracy: 0.8750 - val_loss: 0.5301\n",
      "Epoch 169/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 769ms/step - accuracy: 0.9502 - loss: 0.1217 - val_accuracy: 0.8661 - val_loss: 0.5898\n",
      "Epoch 170/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757ms/step - accuracy: 0.9555 - loss: 0.1057 - val_accuracy: 0.8571 - val_loss: 0.7018\n",
      "Epoch 171/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761ms/step - accuracy: 0.9530 - loss: 0.1497 - val_accuracy: 0.8571 - val_loss: 0.5667\n",
      "Epoch 172/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 766ms/step - accuracy: 0.9602 - loss: 0.1078 - val_accuracy: 0.8661 - val_loss: 0.6149\n",
      "Epoch 173/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9249 - loss: 0.1910 - val_accuracy: 0.8839 - val_loss: 0.4681\n",
      "Epoch 174/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9365 - loss: 0.1886 - val_accuracy: 0.8482 - val_loss: 0.4869\n",
      "Epoch 175/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761ms/step - accuracy: 0.9686 - loss: 0.1026 - val_accuracy: 0.8750 - val_loss: 0.4847\n",
      "Epoch 176/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9528 - loss: 0.1194 - val_accuracy: 0.8929 - val_loss: 0.5301\n",
      "Epoch 177/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9430 - loss: 0.1729 - val_accuracy: 0.8929 - val_loss: 0.4828\n",
      "Epoch 178/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 753ms/step - accuracy: 0.9725 - loss: 0.0790 - val_accuracy: 0.9018 - val_loss: 0.5251\n",
      "Epoch 179/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 775ms/step - accuracy: 0.9677 - loss: 0.0969 - val_accuracy: 0.8750 - val_loss: 0.6085\n",
      "Epoch 180/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 780ms/step - accuracy: 0.9610 - loss: 0.1313 - val_accuracy: 0.8750 - val_loss: 0.5475\n",
      "Epoch 181/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 770ms/step - accuracy: 0.9425 - loss: 0.1229 - val_accuracy: 0.8839 - val_loss: 0.6363\n",
      "Epoch 182/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 755ms/step - accuracy: 0.9734 - loss: 0.0962 - val_accuracy: 0.8393 - val_loss: 0.6699\n",
      "Epoch 183/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.9651 - loss: 0.0877 - val_accuracy: 0.9018 - val_loss: 0.6186\n",
      "Epoch 184/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.9799 - loss: 0.0625 - val_accuracy: 0.8839 - val_loss: 0.5890\n",
      "Epoch 185/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 777ms/step - accuracy: 0.9648 - loss: 0.0795 - val_accuracy: 0.8929 - val_loss: 0.4973\n",
      "Epoch 186/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 768ms/step - accuracy: 0.9471 - loss: 0.1567 - val_accuracy: 0.8839 - val_loss: 0.4705\n",
      "Epoch 187/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.9572 - loss: 0.1252 - val_accuracy: 0.8929 - val_loss: 0.5480\n",
      "Epoch 188/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 765ms/step - accuracy: 0.9596 - loss: 0.1094 - val_accuracy: 0.8750 - val_loss: 0.6272\n",
      "Epoch 189/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 762ms/step - accuracy: 0.9480 - loss: 0.1087 - val_accuracy: 0.8839 - val_loss: 0.5935\n",
      "Epoch 190/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 769ms/step - accuracy: 0.9519 - loss: 0.1146 - val_accuracy: 0.8839 - val_loss: 0.5736\n",
      "Epoch 191/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 764ms/step - accuracy: 0.9702 - loss: 0.0897 - val_accuracy: 0.8750 - val_loss: 0.6543\n",
      "Epoch 192/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 776ms/step - accuracy: 0.9683 - loss: 0.0973 - val_accuracy: 0.8929 - val_loss: 0.7094\n",
      "Epoch 193/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 760ms/step - accuracy: 0.9855 - loss: 0.0387 - val_accuracy: 0.8929 - val_loss: 0.7903\n",
      "Epoch 194/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 767ms/step - accuracy: 0.9652 - loss: 0.0987 - val_accuracy: 0.7589 - val_loss: 0.9123\n",
      "Epoch 195/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 810ms/step - accuracy: 0.9351 - loss: 0.1477 - val_accuracy: 0.8661 - val_loss: 0.7111\n",
      "Epoch 196/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9683 - loss: 0.1472 - val_accuracy: 0.8839 - val_loss: 0.6262\n",
      "Epoch 197/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 763ms/step - accuracy: 0.9569 - loss: 0.1323 - val_accuracy: 0.8482 - val_loss: 0.5373\n",
      "Epoch 198/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 774ms/step - accuracy: 0.9823 - loss: 0.0669 - val_accuracy: 0.8839 - val_loss: 0.6366\n",
      "Epoch 199/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 761ms/step - accuracy: 0.9617 - loss: 0.1467 - val_accuracy: 0.8929 - val_loss: 0.4988\n",
      "Epoch 200/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758ms/step - accuracy: 0.9741 - loss: 0.1250 - val_accuracy: 0.9196 - val_loss: 0.5654\n"
     ]
    }
   ],
   "source": [
    "# Training & Validation\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs = 200, \n",
    "                    shuffle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Saving Model\n",
    "model.save(r'C:\\Users\\ghass\\Desktop\\DMSA-Net\\models\\dmsa_model_91_96.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f4fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9199 - loss: 0.6761\n",
      "Loss = 0.5654471516609192\n",
      "Test Accuracy = 0.9196428656578064\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "preds = model.evaluate(val_generator)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.85      0.95      0.90        43\n",
      "pathological       0.97      0.90      0.93        69\n",
      "\n",
      "    accuracy                           0.92       112\n",
      "   macro avg       0.91      0.93      0.92       112\n",
      "weighted avg       0.92      0.92      0.92       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on validation/test set\n",
    "y_pred_prob = model.predict(val_generator, verbose=1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Extract true labels from generator\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_names = list(val_generator.class_indices.keys())\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
